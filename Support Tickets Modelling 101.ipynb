{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an introductory description of Text Data Analytics using Support Tickets Data. The data is taken from this case study done by Microsoft & Endava hosted at https://github.com/karolzak/support-tickets-classification. \n",
    "\n",
    "The github repository contains nice python code to build an Naive Bayes & SVM models to predict multiple categorical labels for the tickets. They also used GridSearchCV to search for the optimal hyper parameters for these models. The code presented is quite well commented but can be daunting to understand for a beginner. \n",
    "\n",
    "Here i try to break up that code bit by bit to understand the transformations performed by every function. Interestingly all imports will be done just before they are needed, so that it is clear what package is adding what bits in the overall analysis. So Lets begin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48549, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>ticket_type</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category1</th>\n",
       "      <th>sub_category2</th>\n",
       "      <th>business_service</th>\n",
       "      <th>urgency</th>\n",
       "      <th>impact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>hi since recruiter lead permission approve req...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>connection with icon</td>\n",
       "      <td>icon dear please setup icon per icon engineers...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>work experience user</td>\n",
       "      <td>work experience user hi work experience studen...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>requesting for meeting</td>\n",
       "      <td>requesting meeting hi please help follow equip...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reset passwords for external accounts</td>\n",
       "      <td>re expire days hi ask help update passwords co...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>76</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title  \\\n",
       "0                                    NaN   \n",
       "1                   connection with icon   \n",
       "2                   work experience user   \n",
       "3                 requesting for meeting   \n",
       "4  reset passwords for external accounts   \n",
       "\n",
       "                                                body  ticket_type  category  \\\n",
       "0  hi since recruiter lead permission approve req...            1         4   \n",
       "1  icon dear please setup icon per icon engineers...            1         6   \n",
       "2  work experience user hi work experience studen...            1         5   \n",
       "3  requesting meeting hi please help follow equip...            1         5   \n",
       "4  re expire days hi ask help update passwords co...            1         4   \n",
       "\n",
       "   sub_category1  sub_category2  business_service  urgency  impact  \n",
       "0              2             21                71        3       4  \n",
       "1             22              7                26        3       4  \n",
       "2             13              7                32        3       4  \n",
       "3             13              7                32        3       4  \n",
       "4              2             76                 4        3       4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Data\n",
    "import pandas as pd\n",
    "tkts = pd.read_csv(\"all_tickets.csv\")\n",
    "print(tkts.shape)\n",
    "tkts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 48549 support tickets raised by users. The interesting column here is \"body\", which contains the \"text of Subject\" + \"text of email body\" written by user. Also worth noting is that the dataset has been very effectively cleaned in a different script in repo, which saves us a lot of hassles.\n",
    "In NLP terms each of the body elements is a document and the casestudy built various document classification models on top of it. In default settings the column \"ticket_type\" is predicted using Naive Bayes algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    48549.000000\n",
       "mean       266.640178\n",
       "std        384.651236\n",
       "min          2.000000\n",
       "25%         88.000000\n",
       "50%        150.000000\n",
       "75%        275.000000\n",
       "max       7011.000000\n",
       "Name: body_len, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkts['body_len'] = tkts['body'].str.len()\n",
    "tkts['body_len'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the text data field is as small as 2 characters & as large as 7011 characters. Mean length is 266.6. Let us see the size of vocabulary by counting number of unique words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 12259\n"
     ]
    }
   ],
   "source": [
    "unqwords = set()\n",
    "tkts['body'].str.split().apply(unqwords.update)\n",
    "print('Count:', len(unqwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So One Hot Encoding Feature representation for the dataset would be a matrix of 12259 X 48549 size. \n",
    "607 Million binary values amounting to a size of 607Mb. The size here might not be intimidating since sample \n",
    "size is quite small for a NLP problem. Also this model will not work if any new word is present in the \n",
    "unseen test data.\n",
    "\n",
    "In the first exercise, let us try to predict ticket_type field for a ticket. Let us see what valuee this \n",
    "column contain, along with its distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    34621\n",
       "0    13928\n",
       "Name: ticket_type, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkts.ticket_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ticket_type is a categorical variable with 2 values (0 & 1). \n",
    "The class distribution is not ideal, but neither too extreme. In case class distribution is too skewed, we can\n",
    "consider passing in the minority class data multiple times, to balance the skewness. Let us move forward towards building a model. \n",
    "The biggest challenge in building a machine learning model (or statistical model) for NLP data is its unstructured format. The solution is to convert the unstructured text document into structured format by computing some of its properties. \n",
    "\n",
    "Simplest properties can be to compute lenght of the document in chars (or words / lines etc). In case the task was to classify wheather a document is a novel or a news article, even such a simple feature might be enough. Here let us just try to see the correlation of ticket_type of length of document as a fun exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1b7f849a940>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.scatter(tkts.ticket_type, tkts.body_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_type</th>\n",
       "      <th>body_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ticket_type</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.112221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_len</th>\n",
       "      <td>-0.112221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ticket_type  body_len\n",
       "ticket_type     1.000000 -0.112221\n",
       "body_len       -0.112221  1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkts[['ticket_type', 'body_len']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the scatterplot and correlation matrix, there is no significant correlation between between ticket_type and body_len. Let us move towards a more formal approach. \n",
    "\n",
    "Now coming to formal methods as introduced in NLP classes, we can create a vocabulary of most frequent words, say 1000 most frequent words. Then we can create a 1000 length feature vector, where every feature is 0 or 1 depending on if the particular word is present in the document of not. A variant of method 3 can store the number of times the word occurred in a document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48549, 12258)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "cv_docs = cv.fit_transform(tkts['body'])\n",
    "cv_docs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained earlier, we have a 48549 documents X 12258 unique words matrix of tf-idf scores for our document \n",
    "corpus. Let us build a Multinomial Naive Bayes Classifier now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38839, 12258)\n",
      "(9710, 12258)\n"
     ]
    }
   ],
   "source": [
    "label_data = tkts['ticket_type']\n",
    "data = cv_docs\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data, train_label, test_label = train_test_split(data, label_data, test_size=0.2)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:0.9926879505664263\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(train_data, train_label)\n",
    "\n",
    "pred_label = mnb.predict(test_data)\n",
    "prediction_acc = np.mean(pred_label == test_label)\n",
    "print('Model Accuracy:' + str(prediction_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concept of TF-IDF: In NLP Classification problems, it is seen that certain words are very good indicators of a document class. Say if the word \"inflation\" appears multiple times in a document, it is quite certain that the document is from a economics journal. This property of counting the number of occurrences of a given word is called Terf Frequency (TF). However there is another category of words which are very common - fillers. These are words like \"the\", \"of\", \"from\" etc, which are very common in any english text. Since these words add little information in classification, Inverse Document Frequency is computed to reduce the weights of these terms. IDF basically computes inverse of number of documents in which a word is present. Generally it is computed as a logarithm of ratio of total documents and number of documents containing the term. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38839, 12258)\n",
      "(9710, 12258)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vec = TfidfVectorizer(use_idf=True)\n",
    "tfidf_vec_docs = tfidf_vec.fit_transform(tkts['body'])\n",
    "tfidf_vec_docs.shape\n",
    "\n",
    "label_data = tkts['ticket_type']\n",
    "data = tfidf_vec_docs\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data, train_label, test_label = train_test_split(data, label_data, test_size=0.2)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:0.9942327497425335\n",
      "Model F-Score:0.9959213401310998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(train_data, train_label)\n",
    "\n",
    "pred_label = mnb.predict(test_data)\n",
    "prediction_acc = np.mean(pred_label == test_label)\n",
    "print('Model Accuracy:' + str(prediction_acc))\n",
    "\n",
    "#Compute F Score\n",
    "from sklearn.metrics import f1_score\n",
    "f_score = f1_score(test_label, pred_label)\n",
    "print(\"Model F-Score:\" + str(f_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Well both Count Based and TFIDF based models give similar accuracy numbers of ~99.3%. Since Class distributions are fairly balanced F-Score is also quire "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
